{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Классификация диалектизмов архангельских говоров\n",
        "\n",
        "В этом ноутбуке представлена модель для классификации диалектизмов, обученная на материале архангельских говоров.\n",
        "\n",
        "Продемонстрируем, как использовать эту модель для классификации новых слов.\n"
      ],
      "metadata": {
        "id": "61-Eu2W10nkH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qo7mpAT-Ioj-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# в словаре используются следующие символы\n",
        "vocab = 'абвгдежзийклмнопрстуфхцчшщъыьэюя'\n",
        "vocab_to_int = {word: i + 1 for i, word in enumerate(vocab)}\n",
        "\n",
        "# паддинговый символ\n",
        "vocab_to_int['PAD'] = 0\n",
        "\n",
        "vocab_size = len(vocab_to_int.keys())\n",
        "\n",
        "# метки классов\n",
        "dec = ['Фонетическая',\n",
        "       'Грамматическая',\n",
        "       'Словообразовательная',\n",
        "       'Лексическая']\n",
        "\n",
        "\n",
        "def encode(text, max_char_length=20):\n",
        "    '''\n",
        "    Преобразует текст в формат One-Hot Encoding (OHE).\n",
        "\n",
        "    Параметры:\n",
        "    text (str): Входной текст, который нужно преобразовать.\n",
        "    max_char_length (int): Максимальная длина текста для преобразования.\n",
        "                           По умолчанию 20.\n",
        "\n",
        "    Возвращает:\n",
        "    np.ndarray: Массив размером [max_char_length, vocab_size],\n",
        "                где каждый символ текста преобразован в OHE-вектор.\n",
        "    '''\n",
        "\n",
        "    encoded = np.zeros([max_char_length, vocab_size], dtype=int)\n",
        "    i = 0\n",
        "    for letter in text:\n",
        "        if i >= max_char_length:\n",
        "            break\n",
        "        if letter.lower() in vocab_to_int:\n",
        "            encoded[i][vocab_to_int[letter.lower()]] = 1\n",
        "        i += 1\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "8mcchp_IJup-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_word(word, max_char_length=20):\n",
        "    '''\n",
        "    Преобразует слово для подачи на вход нейронной сети.\n",
        "\n",
        "    Параметры:\n",
        "    word (str): Входное слово, которое нужно преобразовать.\n",
        "    max_char_length (int): Максимальная длина слова для преобразования.\n",
        "                           По умолчанию 20.\n",
        "\n",
        "    Возвращает:\n",
        "    np.ndarray: Массив размером [max_char_length, vocab_size],\n",
        "                где каждый символ текста преобразован в OHE-вектор.\n",
        "    '''\n",
        "\n",
        "    word = encode(word.lower().replace('ё', 'е'))\n",
        "    word = word.astype('float32')\n",
        "    word = word.reshape(1, max_char_length, vocab_size)\n",
        "    return word"
      ],
      "metadata": {
        "id": "anh1GkgrJpZw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для примера классификации использованы следующие слова:\n",
        "\n",
        "*   \"наблюдник\" - словообразовательная категория,\n",
        "*   \"рукотерник\" - словообразовательная категория,\n",
        "*   \"жырнов\" - фонетическая категория,\n",
        "*   \"улец\" - фонетическая категория,\n",
        "*   \"складь\" - грамматическая категория,\n",
        "*   \"бывата\" - грамматическая категория,\n",
        "*   \"катанцы\" - лексическая категория,\n",
        "*   \"халупа\" - лексическая категория.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ELodmZ4-Q2Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['наблюдник',\n",
        "         'рукотерник',\n",
        "         'жырнов',\n",
        "         'улец',\n",
        "         'складь',\n",
        "         'бывата',\n",
        "         'катанцы',\n",
        "         'халупа']\n",
        "test_data = {w: encode_word(w) for w in words}"
      ],
      "metadata": {
        "id": "jjtI8luxKfyf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('cnn_uni.keras')\n",
        "for word, encoded_word in test_data.items():\n",
        "    prediction = model.predict(encoded_word)\n",
        "    print(f'{word} принадлежит к категории: ' \\\n",
        "          f'{np.argmax(prediction), dec[np.argmax(prediction)]}.')\n",
        "    print(f'Вероятность по всем классам: {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W03btIVyJaAC",
        "outputId": "929e7396-af02-42fb-995f-e42f59541ae9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
            "наблюдник принадлежит к категории: (2, 'Словообразовательная').\n",
            "Вероятность по всем классам: [[0.00599452 0.00456156 0.8984673  0.09097663]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "рукотерник принадлежит к категории: (2, 'Словообразовательная').\n",
            "Вероятность по всем классам: [[0.00917311 0.00525502 0.93487924 0.05069259]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "жырнов принадлежит к категории: (3, 'Лексическая').\n",
            "Вероятность по всем классам: [[0.13485074 0.11455166 0.21601236 0.53458524]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "улец принадлежит к категории: (0, 'Фонетическая').\n",
            "Вероятность по всем классам: [[0.5758248  0.14848776 0.08798897 0.18769848]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "складь принадлежит к категории: (3, 'Лексическая').\n",
            "Вероятность по всем классам: [[0.23075326 0.17887256 0.2208019  0.36957222]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "бывата принадлежит к категории: (0, 'Фонетическая').\n",
            "Вероятность по всем классам: [[0.3741926  0.1254096  0.14211711 0.3582807 ]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "катанцы принадлежит к категории: (0, 'Фонетическая').\n",
            "Вероятность по всем классам: [[0.36280778 0.13240144 0.19418555 0.31060517]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "халупа принадлежит к категории: (3, 'Лексическая').\n",
            "Вероятность по всем классам: [[0.07509841 0.05588108 0.18505898 0.6839616 ]]\n"
          ]
        }
      ]
    }
  ]
}