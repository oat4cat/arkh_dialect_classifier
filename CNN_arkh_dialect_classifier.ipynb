{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Классификация диалектизмов архангельских говоров\n",
        "\n",
        "В этом ноутбуке представлена модель для классификации диалектизмов, обученная на материале архангельских говоров.\n",
        "\n",
        "Продемонстрируем, как использовать эту модель для классификации новых слов.\n"
      ],
      "metadata": {
        "id": "61-Eu2W10nkH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qo7mpAT-Ioj-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# в словаре используются следующие символы\n",
        "vocab = 'абвгдежзийклмнопрстуфхцчшщъыьэюя'\n",
        "vocab_to_int = {word: i + 1 for i, word in enumerate(vocab)}\n",
        "\n",
        "# паддинговый символ\n",
        "vocab_to_int['PAD'] = 0\n",
        "\n",
        "vocab_size = len(vocab_to_int.keys())\n",
        "\n",
        "# метки классов\n",
        "dec = ['Фонетическая',\n",
        "       'Словообразовательная',\n",
        "       'Лексическая',\n",
        "       'Грамматическая']\n",
        "\n",
        "\n",
        "def encode(text, max_char_length=20):\n",
        "    '''\n",
        "    Преобразует текст в формат One-Hot Encoding (OHE).\n",
        "\n",
        "    Параметры:\n",
        "    text (str): Входной текст, который нужно преобразовать.\n",
        "    max_char_length (int): Максимальная длина текста для преобразования.\n",
        "                           По умолчанию 20.\n",
        "\n",
        "    Возвращает:\n",
        "    np.ndarray: Массив размером [max_char_length, vocab_size],\n",
        "                где каждый символ текста преобразован в OHE-вектор.\n",
        "    '''\n",
        "\n",
        "    encoded = np.zeros([max_char_length, vocab_size], dtype=int)\n",
        "    i = 0\n",
        "    for letter in text:\n",
        "        if i >= max_char_length:\n",
        "            break\n",
        "        if letter.lower() in vocab_to_int:\n",
        "            encoded[i][vocab_to_int[letter.lower()]] = 1\n",
        "        i += 1\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "8mcchp_IJup-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_word(word, max_char_length=20):\n",
        "    '''\n",
        "    Преобразует слово для подачи на вход нейронной сети.\n",
        "\n",
        "    Параметры:\n",
        "    word (str): Входное слово, которое нужно преобразовать.\n",
        "    max_char_length (int): Максимальная длина слова для преобразования.\n",
        "                           По умолчанию 20.\n",
        "\n",
        "    Возвращает:\n",
        "    np.ndarray: Массив размером [max_char_length, vocab_size],\n",
        "                где каждый символ текста преобразован в OHE-вектор.\n",
        "    '''\n",
        "\n",
        "    word = encode(word.lower().replace('ё', 'е'))\n",
        "    word = word.astype('float32')\n",
        "    word = word.reshape(1, max_char_length, vocab_size)\n",
        "    return word"
      ],
      "metadata": {
        "id": "anh1GkgrJpZw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для примера классификации использованы следующие слова:\n",
        "\n",
        "*   \"наблюдник\" - словообразовательная категория,\n",
        "*   \"рукотерник\" - словообразовательная категория,\n",
        "*   \"улеч\" - фонетическая категория,\n",
        "*   \"итти\" - фонетическая категория,\n",
        "*   \"складь\" - грамматическая категория,\n",
        "*   \"бывата\" - грамматическая категория,\n",
        "*   \"катанцы\" - лексическая категория,\n",
        "*   \"халупа\" - лексическая категория.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ELodmZ4-Q2Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['наблюдник',\n",
        "         'рукотерник',\n",
        "         'жырнов',\n",
        "         'улец',\n",
        "         'складь',\n",
        "         'бывата',\n",
        "         'катанцы',\n",
        "         'халупа']\n",
        "test_data = {w: encode_word(w) for w in words}"
      ],
      "metadata": {
        "id": "jjtI8luxKfyf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('cnn_uni.keras')\n",
        "for word, encoded_word in test_data.items():\n",
        "    prediction = model.predict(encoded_word)\n",
        "    print(f'{word} принадлежит к категории:' \\\n",
        "          f'{np.argmax(prediction), dec[np.argmax(prediction)]}.')\n",
        "    print(f'Вероятность по всем классам: {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W03btIVyJaAC",
        "outputId": "d7b61678-a6fe-4b06-ef6f-3aac28d21b7b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
            "наблюдник принадлежит к категории:(1, 'Словообразовательная').\n",
            "Вероятность по всем классам: [[0.04099802 0.7292632  0.20197457 0.02776427]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "рукотерник принадлежит к категории:(1, 'Словообразовательная').\n",
            "Вероятность по всем классам: [[0.05156646 0.83593243 0.08977945 0.02272156]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "жырнов принадлежит к категории:(0, 'Фонетическая').\n",
            "Вероятность по всем классам: [[0.38351968 0.12443283 0.20450273 0.2875447 ]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "улец принадлежит к категории:(0, 'Фонетическая').\n",
            "Вероятность по всем классам: [[0.36255327 0.12864909 0.19026917 0.3185284 ]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "складь принадлежит к категории:(3, 'Грамматическая').\n",
            "Вероятность по всем классам: [[0.3108922  0.10131159 0.1467913  0.4410049 ]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "бывата принадлежит к категории:(2, 'Лексическая').\n",
            "Вероятность по всем классам: [[0.26233214 0.11366124 0.3467272  0.27727944]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "катанцы принадлежит к категории:(2, 'Лексическая').\n",
            "Вероятность по всем классам: [[0.26996627 0.20576534 0.2909594  0.23330908]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "халупа принадлежит к категории:(2, 'Лексическая').\n",
            "Вероятность по всем классам: [[0.12613095 0.12455162 0.5713239  0.17799355]]\n"
          ]
        }
      ]
    }
  ]
}